{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 repositories successfully loaded\n"
     ]
    }
   ],
   "source": [
    "from sourced.engine import Engine\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    ".master(\"local[*]\")\\\n",
    ".appName(\"Examples\")\\\n",
    ".config('spark.executor.memory', '2g')\\\n",
    ".config('spark.executor.cores', '2')\\\n",
    ".config('spark.cores.max', '2')\\\n",
    ".config('spark.driver.memory','2g')\\\n",
    ".getOrCreate()\n",
    "\n",
    "engine = Engine(spark, \"/repositories\", \"siva\")\n",
    "\n",
    "print(\"%d repositories successfully loaded\" % (engine.repositories.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repositories schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = false)\n",
      " |-- urls: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- is_fork: boolean (nullable = true)\n",
      " |-- repository_path: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine.repositories.printSchema()\n",
    "# engine.repositories.select()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repository_id: string (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- hash: string (nullable = false)\n",
      " |-- is_remote: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine.repositories.references.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commits schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repository_id: string (nullable = false)\n",
      " |-- reference_name: string (nullable = false)\n",
      " |-- index: integer (nullable = false)\n",
      " |-- hash: string (nullable = false)\n",
      " |-- message: string (nullable = false)\n",
      " |-- parents: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- parents_count: integer (nullable = false)\n",
      " |-- author_email: string (nullable = true)\n",
      " |-- author_name: string (nullable = true)\n",
      " |-- author_date: timestamp (nullable = true)\n",
      " |-- committer_email: string (nullable = true)\n",
      " |-- committer_name: string (nullable = true)\n",
      " |-- committer_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine.repositories.references.commits.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repository_id: string (nullable = false)\n",
      " |-- reference_name: string (nullable = false)\n",
      " |-- index: integer (nullable = false)\n",
      " |-- hash: string (nullable = false)\n",
      " |-- message: string (nullable = false)\n",
      " |-- parents: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- parents_count: integer (nullable = false)\n",
      " |-- author_email: string (nullable = true)\n",
      " |-- author_name: string (nullable = true)\n",
      " |-- author_date: timestamp (nullable = true)\n",
      " |-- committer_email: string (nullable = true)\n",
      " |-- committer_name: string (nullable = true)\n",
      " |-- committer_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine.repositories.references.filter(\"is_remote=true\")\\\n",
    "                              .filter(\"NOT name LIKE 'refs/heads/HEAD' AND name LIKE 'refs/heads/%'\")\\\n",
    "                              .commits.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------------------+-------------------+\n",
      "|repository_id                   |reference_name     |committer_date     |\n",
      "+--------------------------------+-------------------+-------------------+\n",
      "|github.com/gruns/furl           |refs/heads/asdict  |2017-09-02 11:13:48|\n",
      "|github.com/gruns/furl           |refs/heads/asdict  |2017-09-02 11:13:48|\n",
      "|github.com/gruns/furl           |refs/heads/master  |2018-01-11 03:56:53|\n",
      "|github.com/gruns/furl           |refs/heads/master  |2018-01-11 03:56:53|\n",
      "|github.com/gpjt/webgl-lessons   |refs/heads/master  |2013-04-10 18:01:08|\n",
      "|github.com/gpjt/webgl-lessons   |refs/heads/master  |2013-04-10 18:01:08|\n",
      "|github.com/tparisi/webgl-lessons|refs/heads/master  |2015-11-26 22:20:49|\n",
      "|github.com/simongog/sdsl        |refs/heads/gh-pages|2012-08-13 05:33:49|\n",
      "|github.com/simongog/sdsl        |refs/heads/gh-pages|2012-08-13 05:33:49|\n",
      "|github.com/PyCQA/pycodestyle    |refs/heads/gh-502  |2016-06-26 04:00:15|\n",
      "+--------------------------------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = engine.repositories.references.filter(\"is_remote=true\")\\\n",
    "                              .filter(\"NOT name LIKE 'refs/heads/HEAD' AND name LIKE 'refs/heads/%'\")\\\n",
    "                              .commits\n",
    "df.select(\"repository_id\", \"reference_name\", \"committer_date\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get refs with date = latest date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|       repository_id|max(committer_date)|\n",
      "+--------------------+-------------------+\n",
      "|github.com/gruns/...|2018-01-11 03:56:53|\n",
      "|github.com/eomaho...|2016-09-16 15:31:50|\n",
      "|github.com/PyCQA/...|2018-01-24 17:48:24|\n",
      "|github.com/github...|2017-12-12 01:35:04|\n",
      "|github.com/simong...|2012-08-13 05:33:49|\n",
      "|github.com/gpjt/w...|2013-04-10 18:01:08|\n",
      "|github.com/tparis...|2015-11-26 22:20:49|\n",
      "+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = engine.repositories.references.filter(\"is_remote=true\")\\\n",
    "                              .filter(\"NOT name LIKE 'refs/heads/HEAD' AND name LIKE 'refs/heads/%'\")\\\n",
    "                              .commits\n",
    "df.groupBy(\"repository_id\").agg(F.max(\"committer_date\")).show()\n",
    "repo_id_to_latest_commit = df.groupBy(\"repository_id\").agg(F.max(\"committer_date\"))\\\n",
    "                             .withColumnRenamed('repository_id', 'repo_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Get branch with latest commit for each repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------------------------------+-------------------+\n",
      "|repository_id                   |reference_name                  |committer_date     |\n",
      "+--------------------------------+--------------------------------+-------------------+\n",
      "|github.com/tparisi/webgl-lessons|refs/heads/master               |2015-11-26 22:20:49|\n",
      "|github.com/simongog/sdsl        |refs/heads/gh-pages             |2012-08-13 05:33:49|\n",
      "|github.com/eomahony/Numberjack  |refs/heads/master               |2016-09-16 15:31:50|\n",
      "|github.com/gruns/furl           |refs/heads/master               |2018-01-11 03:56:53|\n",
      "|github.com/github/markup        |refs/heads/kivikakk/pass-symlink|2017-12-12 01:35:04|\n",
      "|github.com/gpjt/webgl-lessons   |refs/heads/master               |2013-04-10 18:01:08|\n",
      "+--------------------------------+--------------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conditions = []\n",
    "conditions.append(repo_id_to_latest_commit.repo_id == df.repository_id)\n",
    "conditions.append(repo_id_to_latest_commit[\"max(committer_date)\"] == df.committer_date)\n",
    "branch_with_latest_commit = df.join(repo_id_to_latest_commit, conditions, \"inner\")\\\n",
    "                              .distinct()\\\n",
    "                              .select('repository_id', 'reference_name', \"committer_date\")\n",
    "branch_with_latest_commit.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting train and test sets\n",
    "\n",
    "We can use randomSplit over the repositories DataFrame to get the train and test sets. The same can be done later to get the train and validation sets depending on the specific cross-validation approach used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count 3 || Train count 4 || Test count 2\n"
     ]
    }
   ],
   "source": [
    "data = branch_with_latest_commit\\\n",
    "        .withColumnRenamed('repository_id', 'repo_id')\\\n",
    "        .withColumnRenamed('reference_name', 'ref_name')\\\n",
    "\n",
    "[train, test] = data.randomSplit([0.8, 0.2], seed)\n",
    "\n",
    "print(\"Total count %d || Train count %d || Test count %d\" % (data.count(), train.count(), test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train dataset with Python UASTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get Python blobs with UASTs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get repo_ids and ref_names to filter and avoid extracting UASTs on all blobs\n",
    "repo_ids, ref_names = set(), set()\n",
    "\n",
    "# Get python list of Row objects contain repository_id and reference_name\n",
    "repo_ref_list = branch_with_latest_commit.select(\"repository_id\", \"reference_name\").collect()\n",
    "for row in repo_ref_list: \n",
    "    repo_ids.add(row.repository_id)\n",
    "    ref_names.add(row.reference_name)\n",
    "\n",
    "languages = [\"Python\"]\n",
    "# Get blobs with UASTs\n",
    "blobs = df.blobs\n",
    "filtered_blobls = blobs\\\n",
    "                    .repartition(2)\\\n",
    "                    .filter(blobs.repository_id.isin(repo_ids))\\\n",
    "                    .filter(blobs.reference_name.isin(ref_names))\\\n",
    "                    .classify_languages()\\\n",
    "                    .filter(\"is_binary = false\")\\\n",
    "                    .filter(F.col(\"lang\").isin(languages))\\\n",
    "                    .dropDuplicates(['blob_id'])\\\n",
    "                    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_uasts = python_blobs\\\n",
    "    .repartition(32)\\\n",
    "    .extract_uasts()\\\n",
    "    .drop(\"content\")\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_uasts.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join python_blobs dataframe with the train dataframe to get UASTS we want to use for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_python = train\\\n",
    "    .join(python_uasts, \n",
    "       (train.repo_id == python_uasts.repository_id) \n",
    "        & (train.ref_name == python_uasts.reference_name))\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_python.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- repo_id: string (nullable = false)\n",
      " |-- ref_name: string (nullable = false)\n",
      " |-- index: integer (nullable = false)\n",
      " |-- hash: string (nullable = false)\n",
      " |-- message: string (nullable = false)\n",
      " |-- parents: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- parents_count: integer (nullable = false)\n",
      " |-- author_email: string (nullable = true)\n",
      " |-- author_name: string (nullable = true)\n",
      " |-- author_date: timestamp (nullable = true)\n",
      " |-- committer_email: string (nullable = true)\n",
      " |-- committer_name: string (nullable = true)\n",
      " |-- committer_date: timestamp (nullable = true)\n",
      " |-- blob_id: string (nullable = true)\n",
      " |-- commit_hash: string (nullable = true)\n",
      " |-- repository_id: string (nullable = true)\n",
      " |-- reference_name: string (nullable = true)\n",
      " |-- is_binary: boolean (nullable = false)\n",
      " |-- path: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- uast: array (nullable = false)\n",
      " |    |-- element: binary (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_python.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
